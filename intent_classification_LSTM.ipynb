{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ==== Read, split, encoding =================\n",
    "df = pd.read_csv('data_speech_all.csv', sep='\\t', encoding='utf-8')\n",
    "X  = df['segmented']\n",
    "y  = df['intent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode labels\n",
    "encoder     = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train_enc = encoder.transform(y_train)\n",
    "y_test_enc  = encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create sequence\n",
    "vocabulary_size = 5000\n",
    "\n",
    "tokenizer       = Tokenizer(num_words= vocabulary_size, char_level = False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index      = tokenizer.word_index\n",
    "\n",
    "sequences       = tokenizer.texts_to_sequences(X_train) #mode='tfidf')\n",
    "X_train_enc     = pad_sequences(sequences, maxlen=30)\n",
    "\n",
    "seque_test      = tokenizer.texts_to_sequences(X_test) #mode='tfidf')\n",
    "X_test_enc      = pad_sequences(seque_test, maxlen=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelquora(pretrained_path=\"sgns.zhihu.word\"):\n",
    "    dic_quora = {}\n",
    "    with open(pretrained_path, \"r\", encoding=\"utf-8\", errors='ignore') as list_words:\n",
    "\n",
    "        for line_word in list_words:\n",
    "            if not line_word or line_word.isspace() or line_word.startswith(\"#\"): continue\n",
    "            list_line = line_word.split()\n",
    "            dic_quora[list_line[0]] = np.asarray(list_line[1:], dtype='float32')\n",
    "        #print(self.dic_wiki[\"grand\"].shape)\n",
    "    return dic_quora\n",
    "\n",
    "def embeddingMarix(word_index=word_index,vocabulary_size=5000, EMBEDDING_DIM=300):\n",
    "    dic_quora = modelquora()\n",
    "    embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = dic_quora.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(embedding_dim=100,dropout=0.2,recurrent_dropout=0.2,activation='sigmoid',lr=0.01,pretrained=False,trainable=False):\n",
    "    # default values\n",
    "    vocabulary_size = 5000\n",
    "    sentence_len    = 30\n",
    "    \n",
    "#     embedding_dim   = 100\n",
    "#     dropout        = 0.2\n",
    "#     recurrent_dropout=0.2\n",
    "#     activation      = 'sigmoid'\n",
    "#     lr              = 0.001\n",
    "#     pretrained      = False\n",
    "#     trainable       = False\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    if pretrained:\n",
    "        embedding_matrix = embeddingMarix()\n",
    "        model.add(Embedding(vocabulary_size, 300, input_length=30, weights=[embedding_matrix], trainable=trainable))\n",
    "    model.add(Embedding(vocabulary_size, embedding_dim, input_length=30))\n",
    "    model.add(LSTM(100,dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "    model.add(Dense(8, activation=activation))\n",
    "    opt = Adam(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "#    embedding_dim=[100,200],\n",
    "    dropout=[0.0, 0.4],\n",
    "    recurrent_dropout=[0.0, 0.4],\n",
    "    activation=['sigmoid','relu','tanh'],\n",
    "    lr=[0.01,0.1],\n",
    "#     pretrained=[True, False],\n",
    "#     trainable=[True,False],\n",
    "    batch_size=[50,100],\n",
    "    epochs=[20,40]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train_enc,y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 2,\n",
       " 'error_score': 'raise',\n",
       " 'estimator': <keras.wrappers.scikit_learn.KerasClassifier at 0x120091390>,\n",
       " 'estimator__build_fn': <function __main__.create_model>,\n",
       " 'fit_params': None,\n",
       " 'iid': True,\n",
       " 'n_jobs': 1,\n",
       " 'param_grid': {'activation': ['sigmoid', 'relu', 'tanh'],\n",
       "  'batch_size': [50, 100],\n",
       "  'dropout': [0.0, 0.4],\n",
       "  'epochs': [20, 40],\n",
       "  'lr': [0.01, 0.1],\n",
       "  'recurrent_dropout': [0.0, 0.4]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': None,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=1)\n",
    "grid.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 238us/step\n",
      "2134/2134 [==============================] - 7s 3ms/step\n",
      "2135/2135 [==============================] - 1s 237us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 251us/step\n",
      "2134/2134 [==============================] - 19s 9ms/step\n",
      "2135/2135 [==============================] - 0s 219us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 301us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 0s 233us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 0s 230us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 237us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 235us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 0s 234us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 1s 243us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 0s 233us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 243us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 240us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 253us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 249us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 0s 233us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 255us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 259us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 260us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 254us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 0s 231us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 266us/step\n",
      "2134/2134 [==============================] - 8s 4ms/step\n",
      "2135/2135 [==============================] - 1s 267us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 1s 243us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 1s 253us/step\n",
      "2135/2135 [==============================] - 8s 4ms/step\n",
      "2134/2134 [==============================] - 1s 250us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 1s 245us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 1s 267us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 1s 256us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 1s 255us/step\n",
      "2134/2134 [==============================] - 12s 5ms/step\n",
      "2135/2135 [==============================] - 1s 246us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 0s 178us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 0s 177us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 0s 173us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 213us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 0s 178us/step\n",
      "2134/2134 [==============================] - 10s 4ms/step\n",
      "2135/2135 [==============================] - 0s 178us/step\n",
      "2135/2135 [==============================] - 9s 4ms/step\n",
      "2134/2134 [==============================] - 0s 180us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 0s 178us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 185us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 194us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 0s 183us/step\n",
      "2134/2134 [==============================] - 9s 4ms/step\n",
      "2135/2135 [==============================] - 0s 188us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 170us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 176us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 179us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 196us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 0s 183us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 0s 177us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 178us/step\n",
      "2134/2134 [==============================] - 49s 23ms/step\n",
      "2135/2135 [==============================] - 0s 230us/step\n",
      "2135/2135 [==============================] - 50s 23ms/step\n",
      "2134/2134 [==============================] - 0s 204us/step\n",
      "2134/2134 [==============================] - 14s 7ms/step\n",
      "2135/2135 [==============================] - 0s 174us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 185us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 198us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 187us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 0s 183us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 0s 189us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 196us/step\n",
      "2135/2135 [==============================] - 10s 5ms/step\n",
      "2134/2134 [==============================] - 0s 180us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 0s 184us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 0s 217us/step\n",
      "2134/2134 [==============================] - 10s 5ms/step\n",
      "2135/2135 [==============================] - 0s 181us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 260us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 250us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 255us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 270us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 259us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2135/2135 [==============================] - 1s 260us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 271us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 240us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 250us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 263us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 263us/step\n",
      "2134/2134 [==============================] - 12s 5ms/step\n",
      "2135/2135 [==============================] - 1s 267us/step\n",
      "2135/2135 [==============================] - 12s 5ms/step\n",
      "2134/2134 [==============================] - 1s 248us/step\n",
      "2134/2134 [==============================] - 12s 5ms/step\n",
      "2135/2135 [==============================] - 1s 255us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 1s 272us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 261us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 269us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 1s 262us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 268us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 272us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 262us/step\n",
      "2134/2134 [==============================] - 11s 5ms/step\n",
      "2135/2135 [==============================] - 1s 264us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 269us/step\n",
      "2134/2134 [==============================] - 12s 5ms/step\n",
      "2135/2135 [==============================] - 1s 268us/step\n",
      "2135/2135 [==============================] - 11s 5ms/step\n",
      "2134/2134 [==============================] - 1s 263us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 1s 264us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 1s 276us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 1s 313us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 1s 279us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 1s 269us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 1s 279us/step\n",
      "2134/2134 [==============================] - 14s 6ms/step\n",
      "2135/2135 [==============================] - 1s 308us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 1s 278us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 0s 182us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 0s 230us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 194us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 0s 195us/step\n",
      "2134/2134 [==============================] - 14s 7ms/step\n",
      "2135/2135 [==============================] - 0s 195us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 0s 196us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 208us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 0s 195us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 202us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 0s 198us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 0s 200us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 0s 192us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 203us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 0s 198us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 0s 194us/step\n",
      "2135/2135 [==============================] - 12s 6ms/step\n",
      "2134/2134 [==============================] - 0s 193us/step\n",
      "2134/2134 [==============================] - 12s 6ms/step\n",
      "2135/2135 [==============================] - 0s 194us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 0s 198us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 197us/step\n",
      "2135/2135 [==============================] - 14s 7ms/step\n",
      "2134/2134 [==============================] - 0s 196us/step\n",
      "2134/2134 [==============================] - 14s 6ms/step\n",
      "2135/2135 [==============================] - 0s 195us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 0s 208us/step\n",
      "2134/2134 [==============================] - 14s 7ms/step\n",
      "2135/2135 [==============================] - 0s 221us/step\n",
      "2135/2135 [==============================] - 14s 7ms/step\n",
      "2134/2134 [==============================] - 0s 216us/step\n",
      "2134/2134 [==============================] - 14s 7ms/step\n",
      "2135/2135 [==============================] - 0s 202us/step\n",
      "2135/2135 [==============================] - 14s 6ms/step\n",
      "2134/2134 [==============================] - 0s 203us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 250us/step\n",
      "2135/2135 [==============================] - 14s 6ms/step\n",
      "2134/2134 [==============================] - 0s 198us/step\n",
      "2134/2134 [==============================] - 13s 6ms/step\n",
      "2135/2135 [==============================] - 0s 202us/step\n",
      "2135/2135 [==============================] - 14s 6ms/step\n",
      "2134/2134 [==============================] - 0s 202us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 0s 202us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 295us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 287us/step\n",
      "2135/2135 [==============================] - 13s 6ms/step\n",
      "2134/2134 [==============================] - 1s 280us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 279us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 304us/step\n",
      "2134/2134 [==============================] - 16s 8ms/step\n",
      "2135/2135 [==============================] - 1s 300us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 1s 319us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 290us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 301us/step\n",
      "2134/2134 [==============================] - 14s 7ms/step\n",
      "2135/2135 [==============================] - 1s 280us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 1s 299us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2135/2135 [==============================] - 1s 280us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 1s 309us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 286us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 308us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 1s 279us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 1s 297us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 1s 296us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 1s 302us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 298us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 301us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 290us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 293us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 304us/step\n",
      "2135/2135 [==============================] - 16s 7ms/step\n",
      "2134/2134 [==============================] - 1s 291us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 1s 309us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 300us/step\n",
      "2134/2134 [==============================] - 16s 8ms/step\n",
      "2135/2135 [==============================] - 1s 295us/step\n",
      "2135/2135 [==============================] - 15s 7ms/step\n",
      "2134/2134 [==============================] - 1s 315us/step\n",
      "2134/2134 [==============================] - 15s 7ms/step\n",
      "2135/2135 [==============================] - 1s 306us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 1s 310us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 1s 313us/step\n",
      "2135/2135 [==============================] - 16s 7ms/step\n",
      "2134/2134 [==============================] - 0s 205us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 0s 205us/step\n",
      "2135/2135 [==============================] - 16s 7ms/step\n",
      "2134/2134 [==============================] - 0s 210us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 1s 242us/step\n",
      "2135/2135 [==============================] - 16s 7ms/step\n",
      "2134/2134 [==============================] - 0s 210us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 0s 211us/step\n",
      "2135/2135 [==============================] - 16s 7ms/step\n",
      "2134/2134 [==============================] - 0s 219us/step\n",
      "2134/2134 [==============================] - 17s 8ms/step\n",
      "2135/2135 [==============================] - 0s 212us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 217us/step\n",
      "2134/2134 [==============================] - 17s 8ms/step\n",
      "2135/2135 [==============================] - 0s 211us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 215us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 0s 229us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 0s 211us/step\n",
      "2134/2134 [==============================] - 22s 10ms/step\n",
      "2135/2135 [==============================] - 1s 293us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 218us/step\n",
      "2134/2134 [==============================] - 17s 8ms/step\n",
      "2135/2135 [==============================] - 0s 215us/step\n",
      "2135/2135 [==============================] - 18s 9ms/step\n",
      "2134/2134 [==============================] - 0s 217us/step\n",
      "2134/2134 [==============================] - 16s 8ms/step\n",
      "2135/2135 [==============================] - 0s 214us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 224us/step\n",
      "2134/2134 [==============================] - 17s 8ms/step\n",
      "2135/2135 [==============================] - 0s 224us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 208us/step\n",
      "2134/2134 [==============================] - 19s 9ms/step\n",
      "2135/2135 [==============================] - 1s 235us/step\n",
      "2135/2135 [==============================] - 18s 8ms/step\n",
      "2134/2134 [==============================] - 0s 221us/step\n",
      "2134/2134 [==============================] - 16s 7ms/step\n",
      "2135/2135 [==============================] - 0s 213us/step\n",
      "2135/2135 [==============================] - 17s 8ms/step\n",
      "2134/2134 [==============================] - 0s 210us/step\n",
      "2134/2134 [==============================] - 16s 8ms/step\n",
      "2135/2135 [==============================] - 0s 187us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 0s 217us/step\n",
      "2134/2134 [==============================] - 17s 8ms/step\n",
      "2135/2135 [==============================] - 0s 213us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 0s 201us/step\n",
      "2134/2134 [==============================] - 16s 8ms/step\n",
      "2135/2135 [==============================] - 0s 213us/step\n",
      "2135/2135 [==============================] - 16s 8ms/step\n",
      "2134/2134 [==============================] - 0s 220us/step\n",
      "2134/2134 [==============================] - 18s 9ms/step\n",
      "2135/2135 [==============================] - 1s 253us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 192 out of 192 | elapsed: 302.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x120091390>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'dropout': [0.0, 0.4], 'recurrent_dropout': [0.0, 0.4], 'activation': ['sigmoid', 'relu', 'tanh'], 'lr': [0.01, 0.1], 'batch_size': [50, 100], 'epochs': [20, 40]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_enc,y_train_enc,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42047317812302598"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'batch_size': 100,\n",
       " 'dropout': 0.4,\n",
       " 'epochs': 20,\n",
       " 'lr': 0.01,\n",
       " 'recurrent_dropout': 0.4}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(grid.best_estimator_, 'lstm-best.pkl')\n",
    "# joblib.dump(grid.best_estimator_, 'lstm-in-one.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_table_plot(grid_clf, \n",
    "                          param_name,\n",
    "                          num_results=15,\n",
    "                          negative=False,\n",
    "                          graph=True,\n",
    "                          display_all_params=True):\n",
    "    from matplotlib      import pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import pandas as pd\n",
    "    \n",
    "    clf = grid_clf.best_estimator_\n",
    "    clf_params = grid_clf.best_params_\n",
    "    if negative:\n",
    "        clf_score = -grid_clf.best_score_\n",
    "    else:\n",
    "        clf_score = grid_clf.best_score_\n",
    "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
    "    cv_results = grid_clf.cv_results_\n",
    "\n",
    "    print(\"best parameters: {}\".format(clf_params))\n",
    "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
    "    if display_all_params:\n",
    "        import pprint\n",
    "        pprint.pprint(clf.get_params())\n",
    "\n",
    "    # pick out the best results\n",
    "    # =========================\n",
    "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    if negative:\n",
    "        best_mean = -best_row['mean_test_score']\n",
    "    else:\n",
    "        best_mean = best_row['mean_test_score']\n",
    "    best_stdev = best_row['std_test_score']\n",
    "    best_param = best_row['param_' + param_name]\n",
    "\n",
    "    # display the top 'num_results' results\n",
    "    # =====================================\n",
    "    display(pd.DataFrame(cv_results) \\\n",
    "            .sort_values(by='rank_test_score').head(num_results))\n",
    "    \n",
    "    # plot the results\n",
    "    # ================\n",
    "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
    "\n",
    "    if negative:\n",
    "        means = -scores_df['mean_test_score']\n",
    "    else:\n",
    "        means = scores_df['mean_test_score']\n",
    "    stds = scores_df['std_test_score']\n",
    "    params = scores_df['param_' + param_name]\n",
    "\n",
    "    # plot\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.errorbar(params, means, yerr=stds)\n",
    "\n",
    "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
    "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
    "        plt.plot(best_param, best_mean, 'or')\n",
    "\n",
    "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'activation': 'sigmoid', 'batch_size': 100, 'dropout': 0.4, 'epochs': 20, 'lr': 0.01, 'recurrent_dropout': 0.4}\n",
      "best score:      0.42047 (+/-0.00248)\n",
      "{'activation': 'sigmoid',\n",
      " 'batch_size': 100,\n",
      " 'build_fn': <function create_model at 0x11fa62c80>,\n",
      " 'dropout': 0.4,\n",
      " 'epochs': 20,\n",
      " 'lr': 0.01,\n",
      " 'recurrent_dropout': 0.4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_dropout</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_recurrent_dropout</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>59.199537</td>\n",
       "      <td>29.829307</td>\n",
       "      <td>0.420473</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422951</td>\n",
       "      <td>0.997657</td>\n",
       "      <td>0.417994</td>\n",
       "      <td>0.996253</td>\n",
       "      <td>10.139861</td>\n",
       "      <td>19.639019</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>7.020267e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.140847</td>\n",
       "      <td>10.993221</td>\n",
       "      <td>0.417662</td>\n",
       "      <td>0.993675</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.417799</td>\n",
       "      <td>0.992034</td>\n",
       "      <td>0.417526</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.048954</td>\n",
       "      <td>0.261720</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>1.641208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.410478</td>\n",
       "      <td>8.117293</td>\n",
       "      <td>0.415320</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.434660</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.395970</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>9.361083e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74.492599</td>\n",
       "      <td>10.534037</td>\n",
       "      <td>0.414149</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.414520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413777</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.215593</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.854731</td>\n",
       "      <td>15.229871</td>\n",
       "      <td>0.412509</td>\n",
       "      <td>0.996017</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.397658</td>\n",
       "      <td>0.992502</td>\n",
       "      <td>0.427366</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>14.953297</td>\n",
       "      <td>4.008052</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>3.514635e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.387936</td>\n",
       "      <td>7.891319</td>\n",
       "      <td>0.410401</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.412178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408622</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.477770</td>\n",
       "      <td>0.074490</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>66.846424</td>\n",
       "      <td>9.769886</td>\n",
       "      <td>0.409932</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.406089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413777</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.938925</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>4.683838e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57.442532</td>\n",
       "      <td>8.354141</td>\n",
       "      <td>0.409698</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.418735</td>\n",
       "      <td>0.995783</td>\n",
       "      <td>0.400656</td>\n",
       "      <td>0.995785</td>\n",
       "      <td>0.756367</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>9.881770e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>97.588763</td>\n",
       "      <td>8.604276</td>\n",
       "      <td>0.407590</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.412646</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.402530</td>\n",
       "      <td>0.998126</td>\n",
       "      <td>0.298908</td>\n",
       "      <td>0.479715</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>4.681644e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73.744987</td>\n",
       "      <td>9.885566</td>\n",
       "      <td>0.406418</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.408431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404405</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.466348</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45.968276</td>\n",
       "      <td>9.435332</td>\n",
       "      <td>0.405950</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.418735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393158</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>1.897515</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.340989</td>\n",
       "      <td>7.419314</td>\n",
       "      <td>0.405013</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>6.093415</td>\n",
       "      <td>0.157834</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>369.275149</td>\n",
       "      <td>11.007060</td>\n",
       "      <td>0.402436</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.416393</td>\n",
       "      <td>0.993908</td>\n",
       "      <td>0.388472</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>273.311162</td>\n",
       "      <td>1.896929</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>2.343346e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>85.699636</td>\n",
       "      <td>10.425190</td>\n",
       "      <td>0.390724</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 100, '...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.385948</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.395501</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>16.517587</td>\n",
       "      <td>0.444661</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>2.344113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.155442</td>\n",
       "      <td>8.372759</td>\n",
       "      <td>0.384633</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'activation': 'sigmoid', 'batch_size': 50, 'd...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.373770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395501</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.189549</td>\n",
       "      <td>0.593143</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>2.341918e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "25      59.199537        29.829307         0.420473          0.996955   \n",
       "24      50.140847        10.993221         0.417662          0.993675   \n",
       "8       53.410478         8.117293         0.415320          0.996252   \n",
       "29      74.492599        10.534037         0.414149          0.999766   \n",
       "1       67.854731        15.229871         0.412509          0.996017   \n",
       "4       82.387936         7.891319         0.410401          0.999766   \n",
       "20      66.846424         9.769886         0.409932          0.999532   \n",
       "9       57.442532         8.354141         0.409698          0.995784   \n",
       "13      97.588763         8.604276         0.407590          0.998595   \n",
       "21      73.744987         9.885566         0.406418          0.999766   \n",
       "16      45.968276         9.435332         0.405950          0.999766   \n",
       "0       55.340989         7.419314         0.405013          0.999766   \n",
       "12     369.275149        11.007060         0.402436          0.996252   \n",
       "28      85.699636        10.425190         0.390724          0.999297   \n",
       "5       91.155442         8.372759         0.384633          0.999766   \n",
       "\n",
       "   param_activation param_batch_size param_dropout param_epochs param_lr  \\\n",
       "25          sigmoid              100           0.4           20     0.01   \n",
       "24          sigmoid              100           0.4           20     0.01   \n",
       "8           sigmoid               50           0.4           20     0.01   \n",
       "29          sigmoid              100           0.4           40     0.01   \n",
       "1           sigmoid               50             0           20     0.01   \n",
       "4           sigmoid               50             0           40     0.01   \n",
       "20          sigmoid              100             0           40     0.01   \n",
       "9           sigmoid               50           0.4           20     0.01   \n",
       "13          sigmoid               50           0.4           40     0.01   \n",
       "21          sigmoid              100             0           40     0.01   \n",
       "16          sigmoid              100             0           20     0.01   \n",
       "0           sigmoid               50             0           20     0.01   \n",
       "12          sigmoid               50           0.4           40     0.01   \n",
       "28          sigmoid              100           0.4           40     0.01   \n",
       "5           sigmoid               50             0           40     0.01   \n",
       "\n",
       "   param_recurrent_dropout                                             params  \\\n",
       "25                     0.4  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "24                       0  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "8                        0  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "29                     0.4  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "1                      0.4  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "4                        0  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "20                       0  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "9                      0.4  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "13                     0.4  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "21                     0.4  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "16                       0  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "0                        0  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "12                       0  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "28                       0  {'activation': 'sigmoid', 'batch_size': 100, '...   \n",
       "5                      0.4  {'activation': 'sigmoid', 'batch_size': 50, 'd...   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "25                1           0.422951            0.997657           0.417994   \n",
       "24                2           0.417799            0.992034           0.417526   \n",
       "8                 3           0.434660            0.997188           0.395970   \n",
       "29                4           0.414520            1.000000           0.413777   \n",
       "1                 5           0.397658            0.992502           0.427366   \n",
       "4                 6           0.412178            1.000000           0.408622   \n",
       "20                7           0.406089            1.000000           0.413777   \n",
       "9                 8           0.418735            0.995783           0.400656   \n",
       "13                9           0.412646            0.999063           0.402530   \n",
       "21               10           0.408431            1.000000           0.404405   \n",
       "16               11           0.418735            1.000000           0.393158   \n",
       "0                12           0.400937            1.000000           0.409091   \n",
       "12               13           0.416393            0.993908           0.388472   \n",
       "28               14           0.385948            0.999063           0.395501   \n",
       "5                15           0.373770            1.000000           0.395501   \n",
       "\n",
       "    split1_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "25            0.996253     10.139861       19.639019        0.002478   \n",
       "24            0.995316      0.048954        0.261720        0.000136   \n",
       "8             0.995316      0.024440        0.023046        0.019345   \n",
       "29            0.999532      0.001281        0.215593        0.000371   \n",
       "1             0.999532     14.953297        4.008052        0.014854   \n",
       "4             0.999532      0.477770        0.074490        0.001778   \n",
       "20            0.999063      0.938925        0.035583        0.003844   \n",
       "9             0.995785      0.756367        0.071454        0.009040   \n",
       "13            0.998126      0.298908        0.479715        0.005058   \n",
       "21            0.999532      0.466348        0.760062        0.002013   \n",
       "16            0.999532      1.897515        0.049009        0.012788   \n",
       "0             0.999532      6.093415        0.157834        0.004077   \n",
       "12            0.998595    273.311162        1.896929        0.013961   \n",
       "28            0.999532     16.517587        0.444661        0.004776   \n",
       "5             0.999532      0.189549        0.593143        0.010865   \n",
       "\n",
       "    std_train_score  \n",
       "25     7.020267e-04  \n",
       "24     1.641208e-03  \n",
       "8      9.361083e-04  \n",
       "29     2.341918e-04  \n",
       "1      3.514635e-03  \n",
       "4      2.341918e-04  \n",
       "20     4.683838e-04  \n",
       "9      9.881770e-07  \n",
       "13     4.681644e-04  \n",
       "21     2.341918e-04  \n",
       "16     2.341918e-04  \n",
       "0      2.341918e-04  \n",
       "12     2.343346e-03  \n",
       "28     2.344113e-04  \n",
       "5      2.341918e-04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAH/CAYAAABO00R3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x61f342e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GridSearch_table_plot(grid,\"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  55.34098947,   67.85473144,   52.84680963,   52.69815099,\n",
       "          82.38793647,   91.15544212,   81.18428206,   87.43880105,\n",
       "          53.41047788,   57.44253159,   54.05827904,   74.84900463,\n",
       "         369.27514911,   97.58876312,   98.25634086,  105.62724042,\n",
       "          45.96827602,   45.06535244,   45.39838159,   46.37291241,\n",
       "          66.8464241 ,   73.74498701,   68.27102542,   70.83160794,\n",
       "          50.14084744,   59.1995374 ,  161.3592304 ,   49.81654298,\n",
       "          85.69963551,   74.49259949,   68.66054249,   75.10155582,\n",
       "          61.94903588,   59.8241626 ,   59.30084312,   62.61161506,\n",
       "          95.38836682,  102.62444341,   94.43240845,  101.90436459,\n",
       "          64.81942308,   65.76147258,   62.59382033,   64.82232094,\n",
       "          99.62737691,  114.49933612,  106.91849506,  139.03078437,\n",
       "          51.90416241,   52.16989148,   52.85764444,   53.53420973,\n",
       "          78.36024761,   78.91687512,   72.69461858,   75.64419019,\n",
       "          51.85106099,   54.77852809,   53.9804275 ,   62.62679839,\n",
       "          84.42964756,   85.51162851,   80.33251834,   84.55392396,\n",
       "          73.38976347,   72.89644611,   73.49663949,   78.29061353,\n",
       "         123.18039703,  126.10764384,  110.93441951,  115.58481944,\n",
       "         103.06811011,   79.17649913,   73.4439224 ,   76.99949193,\n",
       "         115.59069383,  122.94185555,  112.93051887,  123.26821005,\n",
       "          59.84110928,   60.6103524 ,   59.24517202,   60.20970488,\n",
       "          83.54814649,   88.38503647,   87.10112119,   93.09693742,\n",
       "          65.19647217,   66.21322346,   64.70429099,   66.38162994,\n",
       "          83.66289949,   88.21450555,   84.026811  ,   88.63576293]),\n",
       " 'mean_score_time': array([  7.41931403,  15.22987103,   7.9671104 ,   7.75096691,\n",
       "          7.89131892,   8.37275934,   7.97641313,   7.99639845,\n",
       "          8.11729312,   8.35414147,   8.40107644,   8.32287598,\n",
       "         11.00705981,   8.60427606,   9.56867456,  10.59217608,\n",
       "          9.43533242,   9.55018401,   9.51732242,   9.36243558,\n",
       "          9.76988637,   9.88556647,   9.87936294,  10.34011209,\n",
       "         10.99322104,  29.82930744,  32.07575417,   9.83815992,\n",
       "         10.42518997,  10.53403664,  10.31418896,  10.33519113,\n",
       "         11.12475109,  10.90805042,  10.94014692,  11.14930534,\n",
       "         11.24787796,  11.40181601,  11.51514053,  11.70770347,\n",
       "         11.81969833,  11.24488699,  11.31341457,  11.52365053,\n",
       "         11.50749755,  12.45718503,  12.3182025 ,  13.14333212,\n",
       "         12.26565301,  12.81173086,  13.30748248,  12.85414684,\n",
       "         13.01432192,  12.43570292,  12.65894008,  12.35229003,\n",
       "         12.48850751,  13.00174749,  13.8271234 ,  14.47621608,\n",
       "         14.18614316,  14.26597464,  13.54866755,  14.19801402,\n",
       "         15.05067396,  14.02085161,  15.66672361,  16.00479901,\n",
       "         14.68664658,  16.13375807,  15.70166242,  15.58461201,\n",
       "         15.94865704,  15.74556077,  15.25990498,  14.97869992,\n",
       "         15.70708513,  15.78566539,  15.28951049,  16.15644777,\n",
       "         15.90681171,  15.63949633,  15.88179755,  16.25439906,\n",
       "         16.91661942,  16.46133113,  19.01278245,  16.80757546,\n",
       "         17.3250674 ,  16.87775242,  17.53804445,  16.94094193,\n",
       "         16.293239  ,  16.4480834 ,  16.19310403,  17.20885706]),\n",
       " 'mean_test_score': array([ 0.40501289,  0.41250878,  0.34082924,  0.31154837,  0.41040056,\n",
       "         0.3846334 ,  0.32583743,  0.35699227,  0.41531975,  0.40969782,\n",
       "         0.35043336,  0.31037714,  0.40243617,  0.4075896 ,  0.33052237,\n",
       "         0.30288124,  0.40594987,  0.37456079,  0.3436402 ,  0.32700867,\n",
       "         0.40993207,  0.40641836,  0.33356758,  0.33544156,  0.41766221,\n",
       "         0.42047318,  0.3356758 ,  0.31014289,  0.39072382,  0.41414851,\n",
       "         0.32935114,  0.32162099,  0.35043336,  0.34036074,  0.33872101,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.34036074,  0.32654017,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.34036074,  0.34036074,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.29655657,  0.34036074,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.34036074,  0.34036074,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.34036074,  0.34036074,\n",
       "         0.34036074,  0.34036074,  0.34036074,  0.34036074,  0.14078239,\n",
       "         0.25439213,  0.34036074,  0.34012649,  0.27149215,  0.09416725,\n",
       "         0.29093464,  0.34036074,  0.15015226,  0.1543687 ,  0.34036074,\n",
       "         0.34036074,  0.1773249 ,  0.2337784 ,  0.34036074,  0.34036074,\n",
       "         0.14078239,  0.1133755 ,  0.33942375,  0.34036074,  0.08573436,\n",
       "         0.19910986,  0.34036074,  0.34036074,  0.29093465,  0.09159054,\n",
       "         0.34036074,  0.2152729 ,  0.20894823,  0.03021785,  0.34036074,\n",
       "         0.34036074]),\n",
       " 'mean_train_score': array([ 0.99976581,  0.99601698,  0.34129605,  0.30849687,  0.99976581,\n",
       "         0.99976581,  0.33732027,  0.35957027,  0.99625227,  0.99578356,\n",
       "         0.34996543,  0.32326085,  0.9962515 ,  0.99859463,  0.33895588,\n",
       "         0.31577669,  0.99976581,  0.99765775,  0.35910583,  0.36074518,\n",
       "         0.99953162,  0.99976581,  0.3417663 ,  0.34410997,  0.99367496,\n",
       "         0.99695496,  0.34200104,  0.32560068,  0.99929721,  0.99976581,\n",
       "         0.35324785,  0.34223841,  0.5193665 ,  0.34035994,  0.39633183,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.34035994,  0.38438804,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.34035994,  0.34035994,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.46893137,  0.34035994,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.34035994,  0.34035994,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.34035994,  0.34035994,\n",
       "         0.34035994,  0.34035994,  0.34035994,  0.34035994,  0.12974579,\n",
       "         0.25439434,  0.34035994,  0.34035994,  0.27057071,  0.10282029,\n",
       "         0.30380886,  0.34035994,  0.15132317,  0.15436767,  0.34035994,\n",
       "         0.34035994,  0.17916031,  0.2356761 ,  0.34035994,  0.34035994,\n",
       "         0.12974579,  0.11337792,  0.33731401,  0.34035994,  0.08993468,\n",
       "         0.18433811,  0.34035994,  0.34035994,  0.30380886,  0.09626335,\n",
       "         0.34035994,  0.22531776,  0.21383697,  0.02108069,  0.34035994,\n",
       "         0.34035994]),\n",
       " 'param_activation': masked_array(data = ['sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid'\n",
       "  'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid'\n",
       "  'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid'\n",
       "  'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid'\n",
       "  'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'relu' 'relu' 'relu' 'relu' 'relu'\n",
       "  'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu'\n",
       "  'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu'\n",
       "  'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'tanh' 'tanh' 'tanh'\n",
       "  'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh'\n",
       "  'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh'\n",
       "  'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_batch_size': masked_array(data = [50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 100 100 100 100 100 100\n",
       "  100 100 100 100 100 100 100 100 100 100 50 50 50 50 50 50 50 50 50 50 50\n",
       "  50 50 50 50 50 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100\n",
       "  100 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 100 100 100 100 100\n",
       "  100 100 100 100 100 100 100 100 100 100 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_dropout': masked_array(data = [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.0 0.0\n",
       "  0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.0 0.0 0.0 0.0\n",
       "  0.0 0.0 0.0 0.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.0 0.0 0.0 0.0 0.0 0.0\n",
       "  0.0 0.0 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
       "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.4\n",
       "  0.4 0.4 0.4 0.4 0.4 0.4],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_epochs': masked_array(data = [20 20 20 20 40 40 40 40 20 20 20 20 40 40 40 40 20 20 20 20 40 40 40 40 20\n",
       "  20 20 20 40 40 40 40 20 20 20 20 40 40 40 40 20 20 20 20 40 40 40 40 20 20\n",
       "  20 20 40 40 40 40 20 20 20 20 40 40 40 40 20 20 20 20 40 40 40 40 20 20 20\n",
       "  20 40 40 40 40 20 20 20 20 40 40 40 40 20 20 20 20 40 40 40 40],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_lr': masked_array(data = [0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1\n",
       "  0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1\n",
       "  0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1\n",
       "  0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1\n",
       "  0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1\n",
       "  0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1 0.01 0.01 0.1 0.1],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_recurrent_dropout': masked_array(data = [0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4\n",
       "  0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4\n",
       "  0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4\n",
       "  0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4\n",
       "  0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4 0.0 0.4\n",
       "  0.0 0.4 0.0 0.4 0.0 0.4],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'sigmoid',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.0,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 20,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.01,\n",
       "   'recurrent_dropout': 0.4},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.0},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 100,\n",
       "   'dropout': 0.4,\n",
       "   'epochs': 40,\n",
       "   'lr': 0.1,\n",
       "   'recurrent_dropout': 0.4}],\n",
       " 'rank_test_score': array([12,  5, 21, 74,  6, 15, 72, 17,  3,  8, 18, 75, 13,  9, 68, 77, 11,\n",
       "        16, 20, 70,  7, 10, 67, 66,  2,  1, 65, 76, 14,  4, 69, 73, 19, 43,\n",
       "        64, 43, 43, 43, 43, 71, 43, 43, 43, 43, 43, 43, 43, 43, 78, 22, 22,\n",
       "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 90, 82, 43, 62,\n",
       "        81, 93, 80, 43, 89, 88, 43, 43, 87, 83, 43, 43, 91, 92, 63, 22, 95,\n",
       "        86, 22, 22, 79, 94, 22, 84, 85, 96, 22, 22], dtype=int32),\n",
       " 'split0_test_score': array([ 0.40093677,  0.39765808,  0.33770492,  0.29508197,  0.41217799,\n",
       "         0.37377049,  0.35925059,  0.35737705,  0.43466042,  0.41873536,\n",
       "         0.35690867,  0.29320843,  0.41639344,  0.41264637,  0.33021078,\n",
       "         0.35081967,  0.41873536,  0.38126464,  0.36065574,  0.31522249,\n",
       "         0.40608899,  0.40843091,  0.34238876,  0.34613583,  0.41779859,\n",
       "         0.42295082,  0.34800937,  0.30632319,  0.38594848,  0.41451991,\n",
       "         0.32693209,  0.32459017,  0.36393443,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.01779859,\n",
       "         0.24496487,  0.34379391,  0.34379391,  0.34379391,  0.02763466,\n",
       "         0.24496487,  0.34379391,  0.1587822 ,  0.1587822 ,  0.34379391,\n",
       "         0.34379391,  0.01779859,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.01779859,  0.13442623,  0.34192037,  0.34379391,  0.02154567,\n",
       "         0.13442623,  0.34379391,  0.34379391,  0.24496487,  0.04590164,\n",
       "         0.34379391,  0.09367681,  0.08103045,  0.01779859,  0.34379391,\n",
       "         0.34379391]),\n",
       " 'split0_train_score': array([ 1.        ,  0.99250235,  0.33411434,  0.28163074,  1.        ,\n",
       "         1.        ,  0.35754452,  0.36504218,  0.99718838,  0.99578257,\n",
       "         0.35238988,  0.32380506,  0.99390816,  0.99906279,  0.341612  ,\n",
       "         0.36644799,  1.        ,  0.99859419,  0.3819119 ,  0.3819119 ,\n",
       "         1.        ,  1.        ,  0.3420806 ,  0.34957826,  0.99203375,\n",
       "         0.99765698,  0.34442362,  0.3149016 ,  0.99906279,  1.        ,\n",
       "         0.3683224 ,  0.35801312,  0.69493908,  0.33692596,  0.33692596,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.33692596,  0.33692596,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.33692596,  0.33692596,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.33692597,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.01452671,\n",
       "         0.26382381,  0.33692596,  0.33692596,  0.33692596,  0.04264292,\n",
       "         0.26382381,  0.33692596,  0.14995314,  0.14995314,  0.33692596,\n",
       "         0.33692596,  0.01452671,  0.33692596,  0.33692596,  0.33692596,\n",
       "         0.01452671,  0.12371134,  0.33083412,  0.33692597,  0.02108716,\n",
       "         0.12371134,  0.33692597,  0.33692597,  0.26382381,  0.04451734,\n",
       "         0.33692597,  0.10684161,  0.08388004,  0.01452671,  0.33692597,\n",
       "         0.33692597]),\n",
       " 'split1_test_score': array([ 0.40909091,  0.42736645,  0.34395502,  0.3280225 ,  0.40862231,\n",
       "         0.39550141,  0.29240862,  0.35660731,  0.39597001,  0.40065605,\n",
       "         0.34395502,  0.32755389,  0.38847235,  0.40253046,  0.33083412,\n",
       "         0.25492034,  0.39315839,  0.3678538 ,  0.32661668,  0.33880038,\n",
       "         0.41377694,  0.40440487,  0.32474227,  0.32474227,  0.41752577,\n",
       "         0.41799438,  0.32333646,  0.31396439,  0.3955014 ,  0.41377694,\n",
       "         0.33177133,  0.31865042,  0.33692596,  0.33692596,  0.33364574,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.33692596,  0.30927835,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.33692596,  0.33692596,\n",
       "         0.33692596,  0.33692596,  0.33692596,  0.24929709,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.33692597,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.33692597,  0.26382381,\n",
       "         0.26382381,  0.33692596,  0.33645736,  0.19915651,  0.16073102,\n",
       "         0.33692596,  0.33692596,  0.14151827,  0.14995314,  0.33692596,\n",
       "         0.33692596,  0.33692596,  0.12371134,  0.33692596,  0.33692596,\n",
       "         0.26382381,  0.0923149 ,  0.33692597,  0.33692597,  0.14995314,\n",
       "         0.26382381,  0.33692597,  0.33692597,  0.33692597,  0.13730084,\n",
       "         0.33692597,  0.33692597,  0.33692597,  0.04264292,  0.33692597,\n",
       "         0.33692597]),\n",
       " 'split1_train_score': array([ 0.99953162,  0.99953162,  0.34847775,  0.335363  ,  0.99953162,\n",
       "         0.99953162,  0.31709602,  0.35409836,  0.99531616,  0.99578455,\n",
       "         0.34754098,  0.32271663,  0.99859485,  0.99812647,  0.33629977,\n",
       "         0.26510539,  0.99953162,  0.99672131,  0.33629977,  0.33957845,\n",
       "         0.99906323,  0.99953162,  0.34145199,  0.33864168,  0.99531616,\n",
       "         0.99625293,  0.33957846,  0.33629977,  0.99953162,  0.99953162,\n",
       "         0.3381733 ,  0.3264637 ,  0.34379391,  0.34379391,  0.45573771,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.43185012,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.60093677,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.34379391,  0.24496487,\n",
       "         0.24496487,  0.34379391,  0.34379391,  0.20421546,  0.16299766,\n",
       "         0.34379391,  0.34379391,  0.15269321,  0.1587822 ,  0.34379391,\n",
       "         0.34379391,  0.34379391,  0.13442623,  0.34379391,  0.34379391,\n",
       "         0.24496487,  0.1030445 ,  0.34379391,  0.34379391,  0.1587822 ,\n",
       "         0.24496487,  0.34379391,  0.34379391,  0.34379391,  0.14800937,\n",
       "         0.34379391,  0.34379391,  0.34379391,  0.02763466,  0.34379391,\n",
       "         0.34379391]),\n",
       " 'std_fit_time': array([  6.09341466e+00,   1.49532965e+01,   1.88635850e+00,\n",
       "          3.51695895e-01,   4.77770448e-01,   1.89549088e-01,\n",
       "          8.35715055e-01,   1.35065627e+00,   2.44400501e-02,\n",
       "          7.56367445e-01,   1.27796888e-01,   1.73136445e+01,\n",
       "          2.73311162e+02,   2.98908114e-01,   2.46803880e-01,\n",
       "          2.95273232e+00,   1.89751506e+00,   2.22848654e-01,\n",
       "          5.67777514e-01,   1.14777088e-02,   9.38925028e-01,\n",
       "          4.66347933e-01,   1.15321398e-01,   3.48505139e-01,\n",
       "          4.89535332e-02,   1.01398615e+01,   9.90931356e+00,\n",
       "          2.05312788e+00,   1.65175874e+01,   1.28149986e-03,\n",
       "          5.19052505e-01,   3.85169029e-01,   4.99546051e-01,\n",
       "          1.20974779e-02,   3.65039945e-01,   4.43581343e-02,\n",
       "          9.21238065e-01,   1.30357444e+00,   2.74944663e-01,\n",
       "          1.41556740e+00,   3.11416030e-01,   8.97234559e-01,\n",
       "          3.17783594e-01,   1.71298981e-01,   3.66125941e-01,\n",
       "          7.16619134e-01,   2.10585892e+00,   2.00344505e+01,\n",
       "          7.25300550e-01,   2.78476477e-02,   1.85986745e+00,\n",
       "          8.06251526e-01,   3.76275539e-01,   6.98529005e-01,\n",
       "          8.54467511e-01,   1.28213048e-01,   5.18152833e-01,\n",
       "          1.03849053e-01,   3.45800400e-01,   1.38624239e+00,\n",
       "          5.95340371e-01,   2.64026523e-01,   1.73448133e+00,\n",
       "          3.29013693e+00,   3.23446739e+00,   3.41166389e+00,\n",
       "          5.97324061e+00,   2.19732773e+00,   2.16065884e-01,\n",
       "          3.69371891e+00,   5.46090484e-01,   5.97976565e-01,\n",
       "          2.64086121e+01,   7.72644997e-01,   6.93139434e-01,\n",
       "          6.88180208e-01,   1.24439120e-01,   2.18421578e-01,\n",
       "          1.71319962e-01,   2.16995513e+00,   2.81978607e-01,\n",
       "          9.91120458e-01,   4.29674149e-01,   1.06471062e-01,\n",
       "          1.46429539e-01,   1.12517953e+00,   6.38864040e-01,\n",
       "          8.02382231e-01,   4.48709011e-01,   1.13839960e+00,\n",
       "          1.08745897e+00,   6.99141026e-02,   2.68754959e-02,\n",
       "          1.00897157e+00,   4.35215116e-01,   2.39429402e+00]),\n",
       " 'std_score_time': array([  1.57833934e-01,   4.00805211e+00,   2.49313593e-01,\n",
       "          4.46093082e-03,   7.44899511e-02,   5.93143463e-01,\n",
       "          1.17329359e-02,   2.65564919e-02,   2.30460167e-02,\n",
       "          7.14535713e-02,   9.68658924e-03,   2.55069733e-02,\n",
       "          1.89692903e+00,   4.79714990e-01,   4.70544577e-01,\n",
       "          1.10129225e+00,   4.90094423e-02,   3.67898941e-01,\n",
       "          3.89343500e-02,   4.28466797e-02,   3.55833769e-02,\n",
       "          7.60062456e-01,   2.39959955e-02,   1.07837915e-02,\n",
       "          2.61719942e-01,   1.96390194e+01,   1.75975530e+01,\n",
       "          6.31829500e-02,   4.44661140e-01,   2.15592623e-01,\n",
       "          3.41972113e-01,   1.99588895e-01,   3.22284937e-01,\n",
       "          7.62025118e-02,   2.37011909e-03,   1.86243534e-01,\n",
       "          3.21167707e-02,   1.36676908e-01,   3.15928459e-03,\n",
       "          4.56632495e-01,   4.54175472e-01,   1.86529994e-01,\n",
       "          3.33385468e-02,   8.48056078e-02,   2.73314714e-01,\n",
       "          2.91646004e-01,   4.55836535e-01,   6.25489831e-01,\n",
       "          2.00584054e-01,   5.01805067e-01,   5.92716455e-01,\n",
       "          4.17528987e-01,   1.12127900e-01,   1.92798376e-02,\n",
       "          4.01470184e-01,   4.32764173e-01,   1.35073662e-02,\n",
       "          1.49364591e-01,   1.96997404e-01,   1.70392036e-01,\n",
       "          2.30594873e-01,   4.23362374e-01,   7.49496222e-02,\n",
       "          4.18467045e-01,   3.57601881e-01,   6.51473522e-01,\n",
       "          6.89451575e-01,   6.63489699e-01,   4.10771728e-01,\n",
       "          1.87061071e-01,   3.89235616e-01,   9.43261385e-02,\n",
       "          2.91457891e-01,   6.73226953e-01,   4.89028692e-02,\n",
       "          2.49033213e-01,   1.11804962e-01,   3.37366462e-01,\n",
       "          3.01213264e-02,   3.40917945e-01,   4.32844162e-02,\n",
       "          3.56094837e-02,   7.22587109e-02,   3.98656845e-01,\n",
       "          6.47925138e-02,   8.75648975e-01,   2.81831253e+00,\n",
       "          4.91275787e-02,   9.80928540e-01,   2.04367518e-01,\n",
       "          9.96612549e-01,   1.17066681e+00,   2.85682082e-01,\n",
       "          1.91755533e-01,   8.52918625e-02,   1.00817299e+00]),\n",
       " 'std_test_score': array([  4.07707092e-03,   1.48541833e-02,   3.12504740e-03,\n",
       "          1.64702624e-02,   1.77784040e-03,   1.08654562e-02,\n",
       "          3.34209813e-02,   3.84869922e-04,   1.93452070e-02,\n",
       "          9.03965913e-03,   6.47682449e-03,   1.71727295e-02,\n",
       "          1.39605443e-02,   5.05795499e-03,   3.11670951e-04,\n",
       "          4.79496661e-02,   1.27884876e-02,   6.70541847e-03,\n",
       "          1.70195261e-02,   1.17889472e-02,   3.84397679e-03,\n",
       "          2.01301876e-03,   8.82324441e-03,   1.06967808e-02,\n",
       "          1.36411486e-04,   2.47822240e-03,   1.23364526e-02,\n",
       "          3.82059902e-03,   4.77646294e-03,   3.71481197e-04,\n",
       "          2.41961849e-03,   2.96987335e-03,   1.35042321e-02,\n",
       "          3.43397567e-03,   5.07408657e-03,   3.43397567e-03,\n",
       "          3.43397567e-03,   3.43397567e-03,   3.43397567e-03,\n",
       "          1.72577801e-02,   3.43397567e-03,   3.43397567e-03,\n",
       "          3.43397567e-03,   3.43397567e-03,   3.43397567e-03,\n",
       "          3.43397567e-03,   3.43397567e-03,   3.43397567e-03,\n",
       "          4.72484068e-02,   3.43397183e-03,   3.43397183e-03,\n",
       "          3.43397183e-03,   3.43397183e-03,   3.43397183e-03,\n",
       "          3.43397183e-03,   3.43397183e-03,   3.43397183e-03,\n",
       "          3.43397183e-03,   3.43397183e-03,   3.43397183e-03,\n",
       "          3.43397183e-03,   3.43397183e-03,   3.43397183e-03,\n",
       "          3.43397183e-03,   1.23012603e-01,   9.42946765e-03,\n",
       "          3.43397567e-03,   3.66827757e-03,   7.23186976e-02,\n",
       "          6.65481785e-02,   4.59805436e-02,   3.43397567e-03,\n",
       "          8.63196347e-03,   4.41453176e-03,   3.43397567e-03,\n",
       "          3.43397567e-03,   1.59563679e-01,   1.10041283e-01,\n",
       "          3.43397567e-03,   3.43397567e-03,   1.23012602e-01,\n",
       "          2.10556634e-02,   2.49720321e-03,   3.43397183e-03,\n",
       "          6.42037343e-02,   6.46987859e-02,   3.43397183e-03,\n",
       "          3.43397183e-03,   4.59805457e-02,   4.56996007e-02,\n",
       "          3.43397183e-03,   1.21624572e-01,   1.27947757e-01,\n",
       "          1.24221643e-02,   3.43397183e-03,   3.43397183e-03]),\n",
       " 'std_train_score': array([  2.34191814e-04,   3.51463495e-03,   7.18170849e-03,\n",
       "          2.68661296e-02,   2.34191814e-04,   2.34191814e-04,\n",
       "          2.02242491e-02,   5.47190704e-03,   9.36108309e-04,\n",
       "          9.88176953e-07,   2.42444764e-03,   5.44217148e-04,\n",
       "          2.34334620e-03,   4.68164351e-04,   2.65611393e-03,\n",
       "          5.06712993e-02,   2.34191814e-04,   9.36438027e-04,\n",
       "          2.28060671e-02,   2.11667239e-02,   4.68383838e-04,\n",
       "          2.34191814e-04,   3.14306018e-04,   5.46828629e-03,\n",
       "          1.64120812e-03,   7.02026727e-04,   2.42258211e-03,\n",
       "          1.06990859e-02,   2.34411300e-04,   2.34191814e-04,\n",
       "          1.50745492e-02,   1.57747129e-02,   1.75572585e-01,\n",
       "          3.43397577e-03,   5.94058724e-02,   3.43397577e-03,\n",
       "          3.43397577e-03,   3.43397577e-03,   3.43397577e-03,\n",
       "          4.74620786e-02,   3.43397577e-03,   3.43397577e-03,\n",
       "          3.43397577e-03,   3.43397577e-03,   3.43397577e-03,\n",
       "          3.43397577e-03,   3.43397577e-03,   3.43397577e-03,\n",
       "          1.32005400e-01,   3.43397193e-03,   3.43397193e-03,\n",
       "          3.43397193e-03,   3.43397193e-03,   3.43397193e-03,\n",
       "          3.43397193e-03,   3.43397193e-03,   3.43397193e-03,\n",
       "          3.43397193e-03,   3.43397193e-03,   3.43397193e-03,\n",
       "          3.43397193e-03,   3.43397193e-03,   3.43397193e-03,\n",
       "          3.43397193e-03,   1.15219080e-01,   9.42946791e-03,\n",
       "          3.43397577e-03,   3.43397577e-03,   6.63552519e-02,\n",
       "          6.01773677e-02,   3.99850527e-02,   3.43397577e-03,\n",
       "          1.37003473e-03,   4.41453189e-03,   3.43397577e-03,\n",
       "          3.43397577e-03,   1.64633601e-01,   1.01249865e-01,\n",
       "          3.43397577e-03,   3.43397577e-03,   1.15219081e-01,\n",
       "          1.03334220e-02,   6.47989636e-03,   3.43397193e-03,\n",
       "          6.88475213e-02,   6.06267660e-02,   3.43397193e-03,\n",
       "          3.43397193e-03,   3.99850520e-02,   5.17460154e-02,\n",
       "          3.43397193e-03,   1.18476149e-01,   1.29956936e-01,\n",
       "          6.55397491e-03,   3.43397193e-03,   3.43397193e-03])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
